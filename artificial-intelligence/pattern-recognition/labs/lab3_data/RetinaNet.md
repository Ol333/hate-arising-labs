# RetinaNet

## Кто предложил

T. -Y. Lin, P. Goyal, R. Girshick, K. He and P. Dollár, "Focal Loss for Dense Object Detection," in IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 42, no. 2, pp. 318-327, 1 Feb. 2020, doi: 10.1109/TPAMI.2018.2858826. URL: [https://arxiv.org/abs/1708.02002](https://arxiv.org/abs/1708.02002){:target="_blank"}.

## Описание модели

На сегодняшний день детекторы объектов с наивысшей точностью основаны на двухэтапном подходе, популяризированном R-CNN, где классификатор применяется к разреженному набору потенциальных местоположений объектов. Напротив, одноэтапные детекторы, которые применяются к регулярной плотной выборке возможных местоположений объектов, имеют потенциал быть быстрее и проще, но пока отстают от точности двухэтапных детекторов. В этой статье мы исследуем, почему это так. Мы обнаруживаем, что экстремальный дисбаланс классов переднего плана и фона, возникающий во время обучения плотных детекторов, является центральной причиной. Мы предлагаем устранить этот дисбаланс классов, изменив стандартную потерю перекрестной энтропии таким образом, чтобы она снижала вес потери, назначенной хорошо классифицированным примерам. Наша новая фокальная потеря фокусирует обучение на разреженном наборе сложных примеров и не позволяет огромному количеству легких отрицательных примеров перегружать детектор во время обучения. Чтобы оценить эффективность нашей потери, мы проектируем и обучаем простой плотный детектор, который мы называем RetinaNet. Наши результаты показывают, что при обучении с учетом фокальных потерь сеть RetinaNet способна достичь скорости предыдущих одноступенчатых детекторов, превосходя при этом по точности все существующие современные двухступенчатые детекторы.

[статья с хабра](https://habr.com/ru/articles/510560/)


## Фреймворк размещенный авторами на GitHub 

[исходники](?)

[research platform ](https://github.com/facebookresearch/Detectron), в которой в том числе реализована RetinaNet

# Архитектура RetinaNet

RetinaNet — это свёрточная нейронная сеть (CHC) для обнаружения объектов. Её архитектура состоит из 4 основных частей:

## 1. Backbone (Базовая сеть)
Сеть, служащая для извлечения признаков из поступающего на вход изображения. Данная часть сети является вариативной и в её основу могут входить классификационные нейросети, такие как ResNet, VGG, EfficientNet и другие.

---

## 2. Feature Pyramid Network (FPN)
Свёрточная нейронная сеть, построенная в виде пирамиды, служащая для объединения достоинств карт признаков нижних и верхних уровней сети, первые имеют высокое разрешение, но низкую семантическую, обобщающую способность; вторые — наоборот;

---

## 3. Classification Subnet (Подсеть классификации)
- **Назначение:** Обработка признаков из FPN для предсказания классов объектов.
- Использует архитектуру, оптимизированную для точного и эффективного определения вероятностей классов.

---

## 4. Regression Subnet (Подсеть регрессии)
- **Назначение:** Определение координат объектов на изображении (bounding boxes).
- Предсказывает параметры ограничивающих рамок для обнаруженных объектов.

---

## Иллюстрация архитектуры

На изображении ниже представлена структура RetinaNet с использованием ResNet в качестве backbone и интеграцией Feature Pyramid Network. Отдельно показаны подсети классификации и регрессии.

<div class="card border-primary mb-2" style="max-width: 50rem;">
  <div class="card-body">
    <img src="https://habrastorage.org/r/w1560/webt/rt/25/cm/rt25cm_eaw2czxs2lfrgz55yfqq.png"
        alt="alt text" focusable="false" width="100%"
        class="d-block user-select-none" />
  </div>
</div>


---


# Как работает RetinaNet

# 1.Сначала изображение поступает Backbone
## Основные характеристики Backbone

- **Извлечение признаков:**
    - Backbone обрабатывает входное изображение через набор сверточных слоев, постепенно уменьшая пространственное разрешение и извлекая признаки, характеризующие изображение.
    - Полученные карты признаков представляют иерархию, где:
        - Нижние уровни (начальные слои) содержат высокое пространственное разрешение, полезное для детектирования мелких объектов.
        - Верхние уровни (глубокие слои) содержат признаки с большей семантической значимостью, подходящие для крупных объектов.

- **Вариативность архитектур:**
    - RetinaNet допускает использование различных архитектур классификационных моделей в качестве backbone. Наиболее часто используются:
        - ResNet (например, ResNet-50 или ResNet-101): Сети с пропущенными соединениями (skip connections), которые предотвращают затухание градиентов и улучшают обучение глубоких сетей.
        - EfficientNet (семейство EfficientNet-B0–B7): Современная архитектура, оптимизированная для высокой точности и эффективности.
        - VGG (например, VGG-16): Более простая архитектура с глубокими сверточными слоями, но требующая больше ресурсов.

- **Снижение размерности:**
    - Backbone постепенно уменьшает размер карты признаков, увеличивая при этом глубину признаков. Например, для входного изображения размером 224×224 сеть может вернуть карты признаков размером 7×7 с высокой семантической плотностью.

# Процесс работы Backbone

- **Обработка изображения:**
    - Входное изображение преобразуется через начальные сверточные слои, где извлекаются базовые признаки.
    - Эти признаки проходят через серию блоков (например, Bottleneck-блоки в ResNet или MBConv-блоки в EfficientNet), что позволяет получить более сложные представления.

- **Построение иерархии признаков:**
    - Backbone генерирует несколько уровней признаков с разным разрешением. В FPN эти признаки объединяются для улучшения обработки объектов разных масштабов.

- **Выходной результат:**
    - Backbone передаёт карты признаков в FPN для дальнейшей обработки, после чего информация используется для классификации и регрессии.

---

# 2.Пирамида признаков

**Feature Pyramid Network (FPN)** состоит из трёх основных частей:
1. Восходящий путь (*bottom-up pathway*).
2. Нисходящий путь (*top-down pathway*).
3. Боковые соединения (*lateral connections*).


## **1. Восходящий путь (Bottom-Up Pathway)**

- Представляет собой иерархическую «пирамиду» — последовательность сверточных слоёв с уменьшающейся размерностью, которая строится на основе backbone сети.
- **Особенности:**
  - Верхние слои сети имеют большее семантическое значение, но меньшее разрешение.
  - Нижние слои имеют высокое разрешение, полезное для мелких объектов, но содержат меньше семантической информации.
- **Проблема:** На этом этапе возможна потеря важной информации об объекте, например, из-за зашумления небольшого, но значимого объекта фоном. К концу сети информация сильно сжимается и обобщается.
На изображении ниже представлены особенности карт признаков на разных уровнях нейросети
<div class="card border-primary mb-2" style="max-width: 25rem;">
  <div class="card-body">
    <img src="https://habrastorage.org/r/w1560/webt/sj/nt/xn/sjntxnnnavzbhj7ealyvan3b2yq.jpeg"
        alt="alt text" focusable="false" width="100%"
        class="d-block user-select-none" />
  </div>
</div>

## **2. Нисходящий путь (Top-Down Pathway)**

- Карты признаков верхнего слоя пирамиды имеют размер карт признаков верхнего слоя *bottom-up pathway*. Затем они увеличиваются вдвое методом ближайшего соседа для согласования с размерами нижележащих карт признаков.
- **Реализация:**
  - На каждом уровне *top-down* пути карты увеличиваются, чтобы их размеры соответствовали нижележащим картам.
  - Это позволяет восстанавливать пространственную информацию, утраченную на этапе восходящего пути.

На изображении ниже представлено увеличение разрешения изображения методом ближайшего соседа

<div class="card border-primary mb-2" style="max-width: 20rem;">
  <div class="card-body">
    <img src="https://habrastorage.org/r/w1560/webt/h3/yx/su/h3yxsubp9if1hueqenpo-ke-yr8.png"
        alt="Рисунок 4 – Увеличение разрешения изображения методом ближайшего соседа" focusable="false" width="100%"
        class="d-block user-select-none" />
  </div>
</div>



## **3. Боковые соединения (Lateral Connections)**

- **Назначение:** Объединение карт признаков из соответствующих слоёв *bottom-up* и *top-down* пирамид.
- **Процесс:**
  - Карты признаков из *bottom-up* проходят свёртку $1 \times 1$ для уменьшения числа каналов.
  - После этого карты из двух пирамид (с одинаковыми размерами) складываются поэлементно.
- **Результат:** 
  - Сохраняется детальная информация из нижних уровней и семантически важная информация из верхних уровней.

На изображении ниже представлена устройство пирамиды признаков

<div class="card border-primary mb-2" style="max-width: 50rem;">
  <div class="card-body">
    <img src="https://habrastorage.org/r/w1560/webt/k6/ym/lj/k6ymljriq7u_3wbt7z9hm_t2r68.png"
        alt="alt text" focusable="false" width="100%"
        class="d-block user-select-none" />
  </div>
</div>

---

## **Процесс работы Feature Pyramid Network**

1. **Входное изображение обрабатывается в Backbone-сети (восходящий путь):**
   - Генерируются карты признаков разных уровней с уменьшающимся пространственным разрешением и увеличивающейся семантической значимостью.
   - Признаки из Backbone формируют основу для *bottom-up pathway*.

2. **Нисходящий путь (top-down pathway):**
   - Начинается с верхнего уровня карт признаков.
   - Эти карты увеличиваются до размера нижележащих карт методом ближайшего соседа.

3. **Боковые соединения:**
   - Карты признаков *bottom-up* и *top-down* соединяются.
   - Сложение выполняется поэлементно после свёртки $1 \times 1$ для согласования числа каналов.

4. **Выходной результат:**
   - После интеграции карт признаков из *bottom-up* и *top-down* пути FPN передаёт объединённые карты признаков для обработки двумя подсетями (классификация и регрессия).

---

# 3.Подсети классификации и регрессии

Третьей частью архитектуры RetinaNet являются две подсети: классификационная и регрессионная. Каждая из них формирует на выходе результат о классе объекта и его расположении на изображении. Принцип работы этих подсетей не отличается до последнего слоя.

1. **Структура подсетей:**
   - Подсети состоят из 4 слоёв свёрточных сетей, каждый из которых генерирует 256 карт признаков.
   - На пятом слое количество карт признаков изменяется в зависимости от задачи:
     - **Регрессионная подсеть** предсказывает $4 \times A$ карт признаков, где $A$ — количество якорных рамок. Эти значения указывают смещение целевой рамки (*ground-truth box*) относительно якорной рамки.
     - **Классификационная подсеть** генерирует $K \times A$ карт признаков, где $K$ — количество классов объектов. Она предсказывает вероятность принадлежности якорной рамки к определённому классу.

2. **Роль якорных рамок:**
   - **Якорная рамка** (anchor box) — это заранее определённый прямоугольник, относительно которого подсети выполняют обучение и предсказания. В каждой ячейке карты признаков создаются несколько якорных рамок с различными размерами и соотношениями сторон. Например, при размере карты признаков $3 \times 3$ может быть задано 9 якорных рамок для каждой ячейки.
   - Якорные рамки классифицируются как:
     - **Целевые (positive anchors)**, если их пересечение с истинной рамкой (IoU) $\geq 0.5$.
     - **Фоновые (negative anchors)**, если IoU $\leq 0.4$.
     - **Игнорируемые**, если IoU находится между этими порогами.
   - **Целевая рамка (ground-truth box)** — это реальное положение объекта, с которым сравнивается якорная рамка для обучения.
   На изображении ниже представлены якорные рамки для одной ячейки карты признаков с размером 3*3.
   
   <div class="card border-primary mb-2" style="max-width: 30rem;">
    <div class="card-body">
        <img src="https://habrastorage.org/r/w1560/webt/jx/tt/6u/jxtt6uvxbovwik-ak7kowiqibyq.jpeg"
            alt="alt text" focusable="false" width="100%"
            class="d-block user-select-none" />
    </div>
    </div>
3. **Назначение подсетей:**
   - **Классификационная подсеть** определяет, к какому классу относится объект внутри якорной рамки или является ли она фоном.
   - **Регрессионная подсеть** вычисляет координаты и размеры рамок, корректируя положение якорных рамок для точной локализации объектов.  

Таким образом, подсети классификации и регрессии работают совместно с использованием якорных рамок, чтобы предоставить полную информацию о расположении и типе объектов на изображении.

---

# Функции потерь

Потери RetinaNet являются составными, их составляют два значения:
1. Ошибка регрессии, или локализации (обозначена как $L_{\text{loc}}$).
2. Ошибка классификации (обозначена как $L_{\text{cls}}$).

Общая функция потерь записывается как:
$L = \lambda L_{\text{loc}} + L_{\text{cls}}$
где $\lambda$ — гиперпараметр, регулирующий баланс между двумя потерями.


## **1. Ошибка регрессии ($L_{\text{loc}}$)**

### **Выбор якорной рамки:**
- Каждой целевой рамке ($G$) назначается якорная ($A$).
- Эти пары обозначаются как $(A_i, G_i)$, где $N$ — количество сопоставленных пар.

### **Расчёт:**
Для каждого якоря регрессионная сеть предсказывает 4 числа ($P_i = (P_{ix}, P_{iy}, P_{iw}, P_{ih})$):
- $P_{ix}, P_{iy}$ — смещение центров.
- $P_{iw}, P_{ih}$ — разница ширины и высоты.

Соответственно, ошибка регрессии вычисляется как:
$L_{\text{loc}} = \sum_{j \in \{x, y, w, h\}} \text{smoothL1}(P_{ij} - T_{ij}),$
где $T_{ij}$ — истинное смещение.

### **Функция smoothL1**

Функция `smoothL1` используется для вычисления ошибки регрессии (разницы между предсказанными и истинными значениями). Она является сглаженной версией функции абсолютной ошибки (L1), которая уменьшает влияние больших выбросов. Формула выглядит следующим образом:

$\text{smoothL1}(x) =
\begin{cases} 
0.5x^2, & \text{если } \vert x \vert < 1, \\\\\\\\
\vert x \vert - 0.5, & \text{если } \vert x \vert \geq 1.
\end{cases}$

---

### **Пояснение работы формулы:**

1. **Когда $\vert x \vert < 1$:**
   - Используется квадратичная функция $0.5x^2$.
   - Это делает ошибку гладкой и уменьшает её значение для малых разниц $x$.
   - Градиенты в этом случае меньше, что помогает стабильному обучению.

2. **Когда $\vert x \vert \geq 1$:**
   - Используется линейная функция $\vert x \vert - 0.5$.
   - Это уменьшает влияние больших выбросов, поскольку ошибка увеличивается линейно, а не квадратично.

---

### **Зачем нужна функция smoothL1?**
- Она комбинирует преимущества L2-ошибки (гладкость) и L1-ошибки (устойчивость к выбросам).

## **2. Ошибка классификации ($L_{\text{cls}}$)**

Классификационная ошибка в RetinaNet вычисляется с использованием **фокальной функции потерь (Focal Loss)**:
$ L_{\text{cls}} = -\sum_{i=1}^K \alpha_i (1 - p_i)^\gamma \log(p_i),$
где:
- $K$ — количество классов.
- $y_i$ — целевое значение класса.
- $p_i$ — вероятность предсказания $i$-го класса.
- $\gamma$ — параметр фокуса.
- $\alpha$ — коэффициент смещения.

---

## **Особенности Focal Loss:**

- Фокальная функция потерь решает проблему несбалансированности классов, усиливая вклад сложных примеров (объектов).
- Параметр $\gamma$ уменьшает значение ошибки для легко классифицируемых объектов (например, фон).
- Это позволяет нейросети лучше определять объекты, а не только фон.

---

## **Заключение**

Функции потерь RetinaNet эффективно сбалансированы для задач регрессии (определение координат) и классификации (определение класса объекта). Использование **Focal Loss** делает модель более устойчивой к дисбалансу классов.


*Последняя версия: Амелин М.Е.*