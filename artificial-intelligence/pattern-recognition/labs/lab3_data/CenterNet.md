# CenterNet

## Кто предложил

Zhou, Xingyi & Wang, Dequan & Krähenbühl, Philipp. (2019). Objects as Points. DOI: 10.48550/arXiv.1904.07850.  URL: [https://arxiv.org/abs/1904.07850](https://arxiv.org/abs/1904.07850){:target="_blank"}.

## Описание модели

Обнаружение определяет объекты как выровненные по осям блоки на изображении. Большинство успешных детекторов объектов перечисляют почти исчерпывающий список потенциальных местоположений объектов и классифицируют каждое. Это расточительно, неэффективно и требует дополнительной постобработки. В этой статье мы используем другой подход. Мы моделируем объект как одну точку — центральную точку его ограничивающего блока. Наш детектор использует оценку ключевых точек для поиска центральных точек и регрессирует ко всем другим свойствам объекта, таким как размер, трехмерное местоположение, ориентация и даже поза. Наш подход на основе центральной точки, CenterNet, является сквозным дифференцируемым, более простым, быстрым и точным, чем соответствующие детекторы на основе ограничивающего блока. CenterNet достигает наилучшего компромисса скорости и точности на наборе данных MS COCO с 28,1% AP при 142 кадрах в секунду, 37,4% AP при 52 кадрах в секунду и 45,1% AP при многомасштабном тестировании при 1,4 кадрах в секунду. Мы используем тот же подход для оценки 3D-ограничивающего поля в бенчмарке KITTI и позы человека в наборе данных ключевых точек COCO. Наш метод работает на равных с современными многоступенчатыми методами и работает в режиме реального времени.


## Страничка авторов на GitHub 

[исходники](https://github.com/xingyizhou/CenterNet)

## Пример работы

...