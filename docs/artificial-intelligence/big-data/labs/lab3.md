<ol class="breadcrumb">
  <li class="breadcrumb-item"><a href="{{ site.baseurl }}">Главная</a></li>
  <li class="breadcrumb-item"><a href="{{ site.baseurl }}/artificial-intelligence/index.html">ИИ</a></li>
  <li class="breadcrumb-item"><a href="{{ site.baseurl }}/artificial-intelligence/big-data/index.html">Обработка данных</a></li>
  <li class="breadcrumb-item active">ЛР №3</li>
</ol>

<nav>
  <ul></ul>
</nav>

# Линейная регрессия

Теория[<sup>1</sup>](https://github.com/esokolov/ml-course-hse): 
* лекция 1 приведена ниже (подробнее в [pdf]({{ site.baseurl }}/files/AI-big-data/lecture02-linregr.pdf){:target="_blank"});
* [лекция 2]({{ site.baseurl }}/files/AI-big-data/lecture03-linregr.pdf){:target="_blank"}.

Может оказаться полезным посмотреть блокноты [1](https://github.com/esokolov/ml-course-hse/blob/master/2016-fall/seminars/sem01-tools.ipynb), [2](https://github.com/esokolov/ml-course-hse/blob/master/2016-fall/seminars/sem02-linregr.ipynb), [3](https://github.com/esokolov/ml-course-hse/blob/master/2016-fall/seminars/sem03-linregr.ipynb), потому что там есть картинки, хорошие объяснения и примеры кода.

___
## Задание 1

Библиотеки Numpy и Pandas.
[Блокнот]({{ site.baseurl }}/files/AI-big-data/homework-1_0-linregr.ipynb).

[Данные](https://www.kaggle.com/datasets/prajitdatta/data-stories-of-us-airlines) по авиа рейсам.

___

### 1. Линейные модели

Линейные регрессионные модели сводятся к суммированию значений признаков с некоторыми весами:

$ a(x) = w_0 + \sum_{j=1}^d w_j x_j $ <a id="eq_1.1" class="float-end">(1.1)</a>

Параметрами модели являются *веса* или *коэффициенты* $w_j$. Вес $w_0$ также называется
свободным коэффициентом или *сдвигом*( bias). Заметим, что сумма в формуле [(1.1)](#eq_1.1)
является скалярным произведением вектора признаков на вектор весов.
Воспользуемся этим и запишем линейную модель в более компактном виде:
 
$ a(x) = w_0 + \langle w,x \rangle $ <a id="eq_1.2" class="float-end">(1.2)</a>

где $ w = (w_1 ,... , w_d) $ -- вектор весов.

Достаточно часто используется следующий приём, позволяющий упростить запись ещё сильнее.
Добавим к признаковому описанию каждого объекта $(d+1)$-й признак, равный единице.
Вес при этом признаке как раз будет иметь смысл свободного коэффициента, и необходимость в слагаемом $w_0$ отпадёт:

$ a(x) = \langle w,x \rangle $

Тем не менее, при такой форме следует соблюдать осторожность и помнить о наличии в выборке специального признака.
Например, мы столкнёмся со сложностями, связанными с этим, когда будем говорить о регуляризации.

За счёт простой формы линейные модели достаточно быстро и легко обучаются, и поэтому популярны при работе с большими объёмами данных.
Также у них мало параметров, благодаря чему удаётся контролировать риск переобучения и использовать их для работы с зашумлёнными данными и с небольшими выборками.

### 2. Измерение ошибки в задачах регрессии

Чтобы обучать регрессионные модели, нужно определиться, как именно измеряется качество предсказаний.
Будем обозначать через $y$ значение целевой переменной, через $a$ — прогноз модели.
Рассмотрим несколько способов оценить отклонение $L(y, a)$ прогноза от истинного ответа.

###### MSE и $R^2$

Основной способ измерить отклонение — посчитать квадрат разности:

$ L(y, a) = (a−y)^2 $

Благодаря своей дифференцируемости эта функция наиболее часто используется в
задачах регрессии. Основанный на ней функционал называется среднеквадратичным
отклонением (mean squared error, MSE):


$ MSE(a, X) = \frac{1}{ℓ} \sum_{i=1}^ℓ (a(x_i)−y_i)^2 $.

Отметим, что величина среднеквадратичного отклонения плохо интерпретируется,
поскольку не сохраняет единицы измерения — так, если мы предсказываем цену
в рублях, то MSE будет измеряться в квадратах рублей. Чтобы избежать этого,
используют корень из среднеквадратичной ошибки (root meansquared error, RMSE):

$ RMSE(a, X) = \sqrt{\frac{1}{ℓ} \sum_{i=1}^ℓ (a(x_i)−y_i)^2} $.

Среднеквадратичная ошибка подходит для сравнения двух моделей или для
контроля качества во время обучения, но не позволяет сделать выводы том, насколько хорошо данная модель решает задачу.
Например, $MSE = 10$ является очень плохим показателем, если целевая переменная принимает значения от $0$ до $1$, и очень хорошим, если целевая переменная лежит в интервале $(10000, 100000)$.
В таких ситуациях вместо среднеквадратичной ошибки полезно использовать *коэффициент детерминации* (или коэффициент $R^2$ ):

$ R^2 (a, X) = 1 − \frac{\sum_{i=1}^ℓ (a(x_i)−y_i)^2}{\sum_{i=1}^ℓ (y_i-\bar y)^2} $ ,

где $ \bar y = \frac{1}{ℓ} \sum_{i=1}^ℓ y_i $ — среднее значение целевой переменной.
Коэффициент детерминации измеряет долю дисперсии, объяснённую моделью, в общей дисперсии целевой
переменной. Фактически, данная мера качества — это нормированная среднеквадратичная ошибка.
Если она близка к единице, то модель хорошо объясняет данные,
если же она близка к нулю, то прогнозы сопоставимы по качеству с константным
предсказанием.

###### MAE

Заменим квадрат отклонения на модуль:

$ L (y, a) = \vert a − y \vert $

Соответствующий функционал называется средним абсолютным отклонением (mean absolute error, MAE):

$ MAE(a, X) = \frac{1}{ℓ} \sum_{i=1}^ℓ \vert a(x_i) − y_i \vert $.

Модуль отклонения не является дифференцируемым, но при этом менее чувствителен к выбросам.
Квадрат отклонения, по сути, делает особый акцент на объектах с сильной ошибкой, и метод обучения будет в первую очередь стараться уменьшить отклонения на таких объектах.
Если же эти объекты являются выбросами (то есть значение целевой переменной на них либо ошибочно, либо относится к другому распределению и должно быть проигнорировано), то такая расстановка акцентов
приведёт к плохому качеству модели.
Модуль отклонения в этом смысле гораздо более терпим к сильным ошибкам.

Приведём ещё одно объяснение того, почему модуль отклонения устойчив к
выбросам, на простом примере. Допустим, все $ℓ$ объектов выборки имеют одинаковые
признаковые описания, но разные значения целевой переменной $y_1 ,... , y_ℓ$. В этом
случае модель должна на всех этих объектах выдать один и тот же ответ. Если мы
выбрали MSE в качестве функционала ошибки, то получаем следующую задачу:

$ \frac{1}{ℓ} \sum_{i=1}^ℓ (a−y_i)^2 → \min\limits_a $

Легко показать, что минимум достигается на среднем значении всех ответов:

$ a_{MSE}^∗ = \frac{1}{ℓ} \sum_{i=1}^ℓ y_i $ .

Если один из ответов на порядки отличается от всех остальных (то есть является
выбросом), то среднее будет существенно отклоняться в его сторону.
Рассмотрим теперь ту же ситуацию, но с функционалом MAE:

$ \frac{1}{ℓ} \sum_{i=1}^ℓ \vert a−y_i \vert → \min\limits_a $

Теперь решением будет медиана ответов:

$ a_{MAE}^∗ = median \\{ y_i \\} _{i=1}^ℓ $ .

Небольшое количество выбросов никак не повлияет на медиану — она существенно
более устойчива к величинам, выбивающимся из общего распределения.

###### MSLE

Перейдём теперь к логарифмам ответов и прогнозов:

$ L(y, a) = (\log(a + 1) − \log(y + 1))^2 $

Соответствующий функционал называется среднеквадратичной логарифмической
ошибкой (mean squared logarithmic error, MSLE). Данная метрика подходит для задач
с неотрицательной целевой переменной.
За счёт логарифмирования ответов и прогнозов мы скорее штрафуем за отклонения в порядке величин, чем за отклонения в их значениях.
Также следует помнить, что логарифм не является симметричной функцией, и поэтому данная функция потерь штрафует заниженные прогнозы сильнее, чем завышенные.


###### MAPE и SMAPE

В задачах прогнозирования обычно измеряется относительная ошибка:

$ L(y, a) = \vert \frac{y-a}{y} \vert $

Соответствующий функционал называется средней абсолютной процентной ошибкой (mean absolute percentage error, MAPE). Данный функционал часто используется в задачах прогнозирования.
Также используется его симметричная модификация (symmetric mean absolute percentage error, SMAPE):

$ L(y, a) = \frac{ \vert y−a \vert }{ ( \vert y \vert + \vert a \vert ) / 2} $

### 3. Обучение линейной регрессии

Чаще всего линейная регрессия обучается с использованием среднеквадратичной ошибки.
В этом случае получаем задачу оптимизации (считаем, что среди признаков есть константный, и поэтому свободный коэффициент не нужен):

$ \frac{1}{ℓ} \sum_{i=1}^ℓ ( \langle w, x_i \rangle - y_i)^2 → \min\limits_w $

Эту задачу можно переписать в матричном виде. Если $X$ — матрица <<объекты-признаки>>, $y$ — вектор ответов, $w$ — вектор параметров, то приходим к виду

$ \frac{1}{ℓ} \Vert Xw - y \Vert^2 → \min\limits_w $ <a id="eq_3.1" class="float-end">(3.1)</a>

где используется обычная $L_2$-норма.
Если продифференцировать данный функционал по вектору $w$, приравнять к нулю и решить уравнение, то получим явную формулу для решения:

$ w = (X^TX)^{−1} X^Ty $ .

Безусловно, наличие явной формулы для оптимального вектора весов — это
большое преимущество линейной регрессии с квадратичным функционалом.
Но данная формула не всегда применима по ряду причин:

* Обращение матрицы — сложная операция с кубической сложностью от количества признаков. Если в выборке тысячи признаков, то вычисления могут стать слишком трудоёмкими. Решить эту проблему можно путём использования численных методов оптимизации.
* Матрица $X^TX$ может быть вырожденной или плохо обусловленной. В этом случае обращение либо невозможно, либо может привести к неустойчивым результатам. Проблема решается с помощью регуляризации, речь о которой пойдёт ниже.

Следует понимать, что аналитические формулы для решения довольно редки
в машинном обучении. Если мы заменим MSE на другой функционал, то найти такую формулу, скорее всего, не получится. Желательно разработать общий подход, в
рамках которого можно обучать модель для широкого класса функционалов. Такой
подход действительно есть для дифференцируемых функций — обсудим его подробнее.

___
## Задание 2

Линейная регрессия.
[Блокнот]({{ site.baseurl }}/files/AI-big-data/homework-1_1-linregr.ipynb).

Про регуляризацию можно почитать во [второй лекции]({{ site.baseurl }}/files/AI-big-data/lecture03-linregr.pdf){:target="_blank"}.

[Данные](https://www.kaggle.com/datasets/prajitdatta/data-stories-of-us-airlines) по авиа рейсам.

На этапе подготовки данных перед обучением потребуется вспомнить то, что было в 1-й лабораторной, только выполнить это с использованием библиотеки scikit-learn или numpy/pandas:

* Удаление пропусков в данных [→]({{ site.baseurl }}/artificial-intelligence/big-data/labs/lab1.html#обработка-недостающих-значений).
* Масштабирование вещественных признаков (нормализация [→]({{ site.baseurl }}/artificial-intelligence/big-data/labs/lab1.html#нормализация)).
* One-hot кодирование (векторизация с некоторыми отличиями [→]({{ site.baseurl }}/artificial-intelligence/big-data/labs/lab1.html#векторизация)).

___

### 4. Градиентный спуск и оценивание градиента

Оптимизационные задачи [(3.1)](#eq_3.1) можно решать итерационно с помощью градиентных методов (или же методов, использующих как градиент, так и информацию о производных более высокого порядка).

#### 4.1. Градиент и его свойства

*Градиентом* функции $f: \Bbb R^d→ \Bbb R$ называется вектор его частных производных:

$ ∇f(x_1 ,... , x_d) = \left( \frac{∂f}{∂x_j} \right) _{j=1}^d $ .

Градиент является направлением наискорейшего роста функции, 
а антиградиент (т.е. $−∇f$) — направлением наискорейшего убывания.
Это ключевое свойство градиента, обосновывающее его использование в методах оптимизации.

#### 4.2. Градиентный спуск

Будет логично стартовать из некоторой точки, сдвинуться в сторону антиградиента, пересчитать антиградиент и снова сдвинуться в его сторону и т.д. Запишем это более формально. Пусть $w^{(0)}$ — начальный набор параметров (например, нулевой или сгенерированный из некоторого случайного распределения).
Тогда градиентный спуск состоит в повторении следующих шагов до сходимости:

$ w^{(k)} = w^{(k−1)} − η_k∇Q(w^{(k−1)}) $ . <a id="eq_4.1" class="float-end">(4.1)</a>

Здесь под $Q(w)$ понимается значение функционала ошибки для набора параметров $w$.

Через $η_k$ обозначается длина шага, которая нужна для контроля скорости движения.
Можно делать её константной: $η_k=c$. При этом если длина шага слишком
большая, то есть риск постоянно <<перепрыгивать>> через точку минимума, а если шаг
слишком маленький, то движение к минимуму может занять слишком много итераций.
Иногда длину шага монотонно уменьшают по мере движения — например, по простой формуле

$ η_k = \frac{1}{k} $ .

Или более сложной формуле:

$ η_k = λ \left( \frac{s_0}{s_0+k} \right) ^p $ ,

где $λ,s_0$ и $p$ — параметры.
На практике достаточно настроить параметр $λ$, а остальным
присвоить разумные значения по умолчанию: $s_0 = 1$, $p = 0.5$, $d = 1 $.

Останавливать итерационный процесс можно, например, при близости градиента к нулю или при слишком малом изменении вектора весов на последней итерации.

Если функционал $Q(w)$ выпуклый, гладкий и имеет минимум $w^∗$, то имеет место
следующая оценка сходимости:

$ \Bbb E [ Q(w^{(k)}) − Q(w^∗) ] =O(1/k) $ .

#### 4.3. Оценивание градиента

Как правило, в задачах машинного обучения функционал $Q(w)$ представим в
виде суммы $ℓ$ функций:

$ Q(w) = \sum_{i=1}^ℓ q_i(w) $ .

В таком виде, например, записан функционал в задаче [(3.1)](#eq_3.1), где отдельные функции $q_i(w)$ соответствуют ошибкам на отдельных объектах.

Проблема метода градиентного спуска [(4.1)](#eq_4.1) состоит в том, что на каждом шаге
необходимо вычислять градиент всей суммы (будем его называть полным градиентом):

$ \nabla_wQ(w) = \sum_{i=1}^ℓ \nabla_wq_i(w) $ .

Это может быть очень трудоёмко при больших размерах выборки.
В то же время точное вычисление градиента может быть не так уж необходимо — как правило, мы
делаем не очень большие шаги в сторону антиградиента, и наличие в нём неточностей не должно сильно сказаться на общей траектории.
Опишем несколько способов оценивания полного градиента.

Оценить градиент суммы функций можно градиентом одного случайно взятого слагаемого.
В этом случае мы получим метод *стохастического градиентного спуска* (stochastic gradient descent, SGD):

$ w^{(k)} = w^{(k−1)} − η_k ∇q_{i_k}(w^{(k−1)}) $ ,

где $i_k$ — случайно выбранный номер слагаемого из функционала. Для выпуклого и
гладкого функционала может быть получена следующая оценка:

$ \Bbb E [Q(w^{(k)}) − Q(w^∗) ] = O(1/ \sqrt{k}) $ .

Таким образом, метод стохастического градиента имеет менее трудоемкие итерации
по сравнению с полным градиентом, но и скорость сходимости унего существенно
меньше.

Отметим одно важное преимущество метода стохастического градиентного спуска.
Для выполнения одного шага в данном методе требуется вычислить градиент лишь одного слагаемого — а поскольку одно слагаемое соответствует ошибке
на одном объекте, то получается, что на каждом шаге необходимо держать в памяти всего один объект из выборки.
Данное наблюдение позволяет обучать линейные
модели на очень больших выборках: можно считывать объекты с диска по одному,
и по каждому делать один шаг метода SGD.

В 2013 году был предложен метод *среднего стохастического градиента* (stochastic
average gradient), который в некотором смысле сочетает низкую сложность итераций стохастического градиентного спуска и высокую скорость сходимости полного
градиентного спуска. В начале работы в нём выбирается первое приближение $w^0$,
и инициализируются вспомогательные переменные $z_i^0$, соответствующие градиентам
слагаемых функционала:

$ z_i^{(0)} = ∇q_i(w^{(0)}), \qquad i = 1,... , ℓ $ .

На $k$-ой итерации выбирается случайное слагаемое $i_k$ и обновляются вспомогательные переменные:

$ z_i^{(k)} = \begin{cases}
  	∇q_i(w^{(k−1)}), & если \, i = i_k; \\\\\\\\
  	z_i^{(k−1)}, & иначе.
  \end{cases}$

Иными словами, пересчитывается один из градиентов слагаемых. Наконец, делается
градиентный шаг:

$ w^{(k)} = w^{(k−1)} − η_k \sum_{i=1}^ℓ z_i^{(k)} $ .

Данный метод имеет такой же порядок сходимости для выпуклых и гладких функционалов, как и обычный градиентный спуск:

$ \Bbb E [ Q(w^{(k)}) − Q(w^∗) ] = O(1/k) $ .

Существует множество других способов получения оценки градиента.
Например, это можно делать без вычисления каких-либо градиентов вообще — достаточно взять случайный вектор $u$ на единичной сфере и домножить его на значение функции в данном направлении:

$ \nabla_w Q(w) = Q(w + δu)u $ .

Можно показать, что данная оценка является несмещённой для сглаженной версии
функционала $Q$.

В задаче оценивания градиента можно зайти ещё дальше.
Если вычислять градиенты $\nabla_w q_i(w)$ сложно, то можно *обучить модель*, которая будет выдавать оценку градиента на основе текущих значений параметров.
Этот подход был предложен для обучения глубинных нейронных сетей.

___
## Задание 3

Градиентный спуск.
[Блокнот]({{ site.baseurl }}/files/AI-big-data/homework-1_2-linregr.ipynb).

Может понадобиться:

$ MSPE = \frac{1}{l}\sum_{i=1}^l \left( \frac{y_i - \langle w, x_i \rangle }{y_i} \right)^2 $

Градиент MSPE по $w$ можно вычислить следующим образом:

$ \frac{\partial}{\partial w} MSPE(w) = \frac{\partial}{\partial w} [\frac{1}{l} \frac{y^Ty - y^TXw - w^TX^Ty + w^TX^TXw}{y^Ty}]. $

Продифференцируем каждое слагаемое отдельно.

$ \frac{\partial}{\partial w} [\frac{y^Ty}{y^Ty}] = 0. $

$ \frac{\partial}{\partial w} [\frac{- y^TXw}{y^Ty}] = \frac{-X^Ty}{y^Ty}. $

$ \frac{\partial}{\partial w} [\frac{- w^TX^Ty}{y^Ty}] = \frac{-X^Ty}{y^Ty}. $

$ \frac{\partial}{\partial w} [\frac{w^TX^TXw}{y^Ty}] = \frac{2X^TXw}{y^Ty}. $

Получаем уравнение

$ \frac{\partial}{\partial w} MSPE(w) = \frac{2}{l} * \frac{X^TXw -X^Ty}{y^Ty} = \frac{2*X^T}{l} * \frac{Xw - y}{y^Ty}. $

___

**Итого, 3 блокнота с выполненными заданиями нужно прислать для проверки на почту *bobrovskaya_op@surgu.ru* или *Smorodinov-1990@mail.ru*.**

<div class="row">
  <div class="col-lg-12">
    <ul class="list-unstyled">
      <li class="float-end">
        <button type="button" class="btn btn-outline-primary" onclick="window.location.href='#линейная-регрессия';">Вверх</button>
      </li>
      <li  class="float-end">
       <button type="button" class="btn btn-primary" onclick="window.location.href='{{ site.baseurl }}/artificial-intelligence/big-data/labs/lab4.html';">ЛР №4 →</button>
     </li>
      <li>
        <button type="button" class="btn btn-primary" onclick="window.location.href='{{ site.baseurl }}/artificial-intelligence/big-data/labs/lab2.html';">← ЛР №2</button>
      </li>
    </ul>
  </div>
</div>
